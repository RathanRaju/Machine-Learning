# Machine Learning

* Machine learning is a method of data analysis that automates analytical model building. 

* It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.

---

### Linear Regression

#### In simple linear regression, we predict scores on one variable from the scores on a second variable. The variable we are predicting is called the criterion variable and is referred to as Y. The variable we are basing our predictions on is called the predictor variable and is referred to as X. When there is only one predictor variable, the prediction method is called simple regression. In simple linear regression, the topic of this section, the predictions of Y when plotted as a function of X form a straight line.

[Linear Regression Example](https://github.com/RathanRaju/Machine-Learning/blob/master/Linear%20Regression%20Project.ipynb)

---

### Logistic Regression

#### Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables

[Logistic Regression Example](https://github.com/RathanRaju/Machine-Learning/blob/master/Logistic%20Regression%20Project.ipynb)

---

### Random Forest Classifier

#### Random forest is a learning algorithm that is supervised. It produces a "forest" out of an ensemble of decision trees, which are normally trained using the "bagging" process. The bagging method's basic premise is that combining different learning models improves the overall outcome.
Random forest is also a valuable algorithm because the default hyperparameters it utilises often make accurate predictions. Understanding the hyperparameters is easy, and there aren't many of them to begin with. 

[Random Forest Classifier Example](https://github.com/RathanRaju/Machine-Learning/blob/master/Customer%20Segmentation%20Classification.ipynb)

--- 

###	Support Vector Classifier

#### Libsvm is used in this implementation. The fit time scales at least quadratically with the number of samples, and above tens of thousands of samples, it may be impractical. Consider using LinearSVC or SGDClassifier instead, probably after a Nystroem transformer, for large datasets. A one-to-one scheme is used to manage multiclass support. 

[Random Forest Classifier Example](https://github.com/RathanRaju/Machine-Learning/blob/master/Customer%20Segmentation%20Classification.ipynb)




